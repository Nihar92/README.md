import requests
from bs4 import BeautifulSoup
import os
from urllib.parse import urljoin

# Function to create a directory if it does not exist
def create_directory(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

# Function to download and save images
def save_images(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    img_tags = soup.find_all('img')

    # Create a directory to save images
    create_directory('images')

    for img in img_tags:
        img_url = img['src']
        if img_url.startswith('http'):
            img_name = img_url.split('/')[-1]
            img_data = requests.get(img_url).content
            with open(os.path.join('images', img_name), 'wb') as f:
                f.write(img_data)
            print(f"Downloaded {img_name}")
        else:
            img_url = urljoin(url, img_url)
            img_name = img_url.split('/')[-1]
            img_data = requests.get(img_url).content
            with open(os.path.join('images', img_name), 'wb') as f:
                f.write(img_data)
            print(f"Downloaded {img_name}")

# Example usage
url = 'https://example.com'  # Replace this with the URL of the webpage containing images
save_images(url)
